            +---------------------------+
            |           CS 140          |
            | PROJECT 3: VIRTUAL MEMORY |
            |       DESIGN DOCUMENT     |
            +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Matthew Mahowald <mcm2018@stanford.edu>
Scott Morris <swmorris@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

            PAGE TABLE MANAGEMENT
            =====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

PAGE.H
/* States the location of the page's frame. */
enum page_location
{
  DISK,  /* Page is a file located on disk. */
  EXEC,  /* Page is an executable file. */
  SWAP,  /* Page has been evicted and placed on the swap. */
  ZERO   /* Page does not exist anywhere, must be alloc'd and zero'd. */
};

/* File data held by an spte. */
struct spte_file
{
  struct file *file;
  off_t ofs;
  size_t read;
  size_t zero;
};

/* Supplementary Page Table Entry

   The spte struct holds data for a single entry in a process's supplementary 
   page table. The purpose of this table is two-fold:

     1. On a page fault, the supplementary page table supplies the kernel with
        the location of the frame, one of three locations defined by the 
        enumeration page_location. 
     2. The kernel uses the supplementary page table to cleanup up memory 
        associated with a process on exit.

   The supplementary page table is defined as a hash table within each 
   process. By placing the hash table as a member of the thread struct, 
   pintOS cannot support sharing, but this allowed the hash function to 
   use the user virtual address rather than the kernel virtual address. */

struct spte 
{
  struct hash_elem elem;        /* Hash element for the spt. */
  uint32_t *pd;                 /* Page directory for the spte's thread. */
  enum page_location location;  /* Location of the frame. */
  void *vaddr;                  /* User virtual address. */
  struct frame *frame;          /* Kernel virtual address. */
  struct spte_file file_data;   /* File information. */
  bool writable;                /* Process has read-write privileges. */
  swapid_t swapid;              /* Sector in swap if in swap. */
};

FRAME.H

struct frame {
    void *paddr;
    struct spte *spte;
    struct list_elem elem;
    bool pinned;
};

struct list frame_free_list;    /* Keeps track of free frames. */
struct list frame_used_list;    /* Keeps track of frames currently in use. */

struct lock free_lock;          /* Used to sync frame_free_list. */
struct lock used_lock;          /* Used to sync frame_used_list. */

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

Our implementation leveraged the supplementary page table to store the
information for the location of the frame. This boils down to two main
page.c functions: page_load and page_unload. There are two cases: First,
the frame could already be loaded, in which case the page_get_spte call
will return a spte pointer with a non-NULL frame address. In the case 
that the frame is NULL, page_load brings the page in from a number of
possible locations. In all cases, a call to frame_get insures an unused 
or evicted frame to which the kernel writes the located data.

1) The frame could be on DISK (includes the EXEC enum case). In this case,
   our implementation reads the data back into the newly populated spte's
   frame. The information of where to read from is stored in the spte_file
   struct, which is loaded in on creation of the spte. One consideration is
   writing back dirtied pages, which is handled in page_unload +++MAYBE 
   EXPAND+++
2) The frame could be evicted and written to the swap partition. This case
   leverages our swap api, which reads the memory corresponding to the 
   swapid stored in the spte using the devices/block.c block_read call.
3) In the final case, the page_load function is called from our page_grow_
   stack function, which requests a zero'd out page. This memsets the frame
   to all 0s.

Finally, page_load updates the pagedir for the current thread so that the
MMU contains the correct mapping of virtual address to physical address.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

I believe:
We avoid the issue entirely by keeping the supplementary page table as
a per-process table.

I believe we only use the supplied user virtual addresses in the kernal. Also, 
we still use palloc for kernel memery (i.e. no spte stuff)

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

There are two cases in frame acquisition â€” when frames are still free, and 
when no frames are free (i.e. a frame needs to be evicted). We'll walk through
how race conditions are avoided in both cases. 

In order to recieve a frame, a process first must acquire the free_lock. This
prevents any other process from accessing the frame free list. If the list is 
not empty, the first free frame is popped before releasing the lock. Thus, the
free list will always remain intact.

If no frame is free, a process releases the free_lock and 

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings

For the spt of each thread, we created a hash table to map the user virtual
addresses to the spte and frame structs. This allowed us to achieve constant 
time lookup of virtual addresses' data. The only time we need to iterate over
the spt is in cleanup.

+++ We could do a free list and the a used array. +++

For our frame data structure, we decided to use two lists: a free list and
a used list. The free list is an auxiliary structure that is populated in 
frame_init with palloc'd pages. This list allows for immediate access to
a free frame. Once all frames are filled, our used list becomes the data
structure that is circularly traversed by the two clock hands to determine
which pages to evict. We decided a list is the most compatible with the
clock algorithm, as it can be iterated over easily.

               PAGING TO AND FROM DISK
               =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We use the two-hand clock cycle algorithm. Two global references to 
used frame list elements iterate over the used list, the first setting
the accesssed bit to false, the second evicting the first frame 
encountered with an accessed bit set to false. 

These two references are guarded by the used frame list lock and are only
updated by one eviction algorithm at a time.

To keep processes from evicting the same frame, we used a lock on the 
frame table (specifically the used frame list). This lock is acquired
and held while our eviction algorithm selects a frame.

As described in B8, we use a pinned flag to avoid evicting frames that
are referenced by other threads in the process of loading a page or
using frame data in a call to sys_read or sys_write.

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

Our spte keeps track of the pagedir of its owner thread. Then, when a process
P evicts a page belonging to Q, P can clear the virtual address from Q's
pagedir through the spte. Additionally, when a page is swapped, we keep 
track of the swap id and update the spte's location to SWAP.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

As described in the assignment spec, a page fault within 32 bytes, defined
as PUSHA_BYTES, of the stack pointer is probably an attempt to grow the 
stack. However, it does not suffice to grow the stack only if the fault
is within the valid region between the esp and esp - PUSHA_BYTES. Because
we lazily allocate to the stack, meaning that when a 20kb array is declared
on the stack no actual memory allocation occurs for those 20kbs--the only 
change is to the stack pointer, our heuristic also includes any address
below PHYS_BASE and above the stack pointer. 

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

- System-wide data has a coarse lock (frame table and swap table.)

- spte locks only can be acquired by eviction and page faulting back in.

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

We avoid P evicting Q's frame and Q faulting the page back in through
a lock in the spte struct. When the page faults, our implementation
loads the page through a call to page_load. In page_load, the lock must
be acquired before any loading, specifically getting a frame, is done.
In eviction, the same lock is acquired before the frame is actually
swapped out. In doing so, we assure that the eviction will finish
before the frame is loaded back in, avoiding race conditions.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

Mixture of B6 and B8? Not sure.

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

Our mechanism for "locking" frames into physical memory is the pinned
boolean flag. In a call to sys_read or sys_write, our implementation
uses a helper function called load_and_pin. This function assures that
the loaded pages that will be used in the system call will not be evicted
by setting the "pinned" flag to true. In our eviction algorithm, we ignore
pages that have been pinned.

This flag has a double purpose, as we want to be sure not to evict pages
that are in the process of being loaded. To that end, frame_get returns
a pinned page, which the page_load function flips only once the page
loading has run to completion.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

Our implementation uses a lock for every spte as described. This is as
fine-grained as we could implement, as it allows for processes to evict and 
page fault in concurrently on different pages seamlessly. Selecting a frame 
to evict,on the other hand, requires a coarse lock over the entire frame 
table, as two processes cannot elect to evict the same frame. 

             MEMORY MAPPED FILES
             ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

typedef int mapid_t;               /* Unique identifier for mmapped files. */

struct mmapped_file
  {
    struct list_elem elem;         /* List elem. */
    mapid_t id;                    /* Identifier (similar to fd). */
    void *start_vaddr;             /* Start of mmapped zone. */
    void *end_vaddr;               /* End of mmapped zone. */
    struct file *file;             /* File mmapped. */
  };  

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

To mmap a file to a process's virtual address space, we add a page for each
PGSIZE chunk of the file into that process's supplemental page table. These
pages are loaded lazily, and uniquely identified with the DISK location. 

Pages located on DISK (i.e., mmapped addresses) are loaded on a page fault
just as we would load pages from the executable file (identified with the EXEC
location). This loading occurs with calls to file_read from the file data 
that is stored in each supplemental page table entry. Pages in SWAP are read
from the swap disk (abstracted to swap.h) and ZERO'd pages (new stack pages) 
are simply memset to 0.

While mmapped pages (in DISK) are loaded more like pages in EXEC, they are
evicted quite differently. Evicted pages are unloaded in our page_unload 
function, which switches based on location. If the user page is dirty (i.e. 
the process has edited the mmapped file), that page is written back to the 
originally mapped file using the same file data stored in the SPTE that was 
originally used to load that user page. Dirty EXEC pages are written to swap
(and their location is changed to SWAP) and dirty SWAP pages (i.e. were loaded
from swap) are likewise written back to swap. Dirty ZERO pages are written to 
swap (and location also changed to SWAP).

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

Our implementation of mmap iterates through the supplied virtual buffer in 
PGSIZE increments. Before adding a new mmapped page to the mapping process's
supplemental page table, we check to see if the SPT already has a page at that
virtual address space. If it does, then there is overlap, so we first remove 
any already-added SPTEs associated with the mmap call in question and return
MAP_FAILED.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

We 

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

